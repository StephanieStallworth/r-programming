# R Course Work
## [Machine Learning A-Z: AI, Python & R (Udemy)](https://www.udemy.com/course/machinelearning/)
### Section 1: Welcome to the Course! 
1. Welcome Challenge!   
2. Machine Learning Demo -  Get Excited!   
3. Get All The Datasets, Codes And Slides Here   
4. How To Use The ML A Z Folder & Google Colab   
5. Installing R And R Studio (Mac, Linux & Windows)   
6. Extra: Use ChatGPT To Boost Your ML Skills  

### Section 2: Part 1 - Data Preprocessing
7. Welcome To Part 1 -  Data Preprocessing 
8. The Machine Learning Process  
9. Splitting The Data Into A Training And Test Set  
10. Feature Scaling 

### Section 3: Data Preprocessing Python
11. Getting Started - Step 1: Get the Dataset  
12. Getting Started - Step 2: Overview 
13. Importing The Libraries  
14. Importing The Dataset - Step 1: `pandas.read_csv()`  
15. Importing The Dataset - Step 2: Independent Variables Matrix 
16. Importing The Dataset - Step 3: Dependent Variable Array 
17. Python Learners, Summary Of OOP: Classes & Objects (Coding Exercise 1: Importing And Preprocessing A Dataset For ML)  
18. Taking Care Of Missing Data - Step 1: `SimpleImputer()` Object 
19. Taking Care Of Missing Data - Step 2: `fit()` `transform()` (Coding Exercise 2: Handling Missing Data in Dataset For ML) 
20. Encoding Categorical Data - Step 1: `sklearn.compose.ColumnTransformer()`  `sklearn.preprocessing.OneHotEncoder()`  
21. Encoding Categorical Data - Step 2: `fit_transform()` 
22. Encoding Categorical Data - Step 3: `LabelEncoder()` Object 
23. Splitting The Dataset Into The Training Set And Test Set - Step 1: Feature Scaling Overview 
24. Splitting The Dataset Into The Training Set And Test Set - Step 2: `train_test_split()` 
25. Splitting The Dataset Into The Training Set And Test Set - Step 3: `train_test_split()` continued... 
26. Feature Scaling - Step 1: Feature Scaling Techniques (Standardization, Normalization) 
27. Feature Scaling - Step 2: `StandardScaler()` Object 
28. Feature Scaling - Step 3: `X_Train` `fit_transform()`
29. Feature Scaling  - Step 4: `x_test` `transform()` only 

### Section 4: Data Preprocessing R
30. Getting Started: Datasets  
31. Dataset Description 
32. Importing The Dataset  
33. Taking Care Of Missing Data  
34. Encoding Categorical Data 
35. Splitting The Dataset Into The Training Set And Test Set - Step 1: `read.csv()`  
36. Splitting The Dataset Into The Training Set And Test Set - Step 2: `sample.split()` 
37. Feature Scaling - Step 1: Feature Scaling R (Normalization, Standardization) 
38. Feature Scaling - Step 2: `scale()` 
39. Data Preprocessing Template  

### Section 5: Part 2 - Regression
40. Welcome To Part 2 -  Regression 

### Section 5: Simple Linear Regression
41. Simple Linear Regression Intuition  
42. Ordinary Least Squares  
43. Simple Linear Regression Python - Step 1A: Get the Dataset  
44. Simple Linear Regression Python - Step 1B: `pandas.read_csv()` 
45. Simple Linear Regression Python - Step 2A: Create Regressor Object `LinearRegression()` 
46. Simple Linear Regression Python -  Step 2B: `fit()` 
47. Simple Linear Regression Python - Step 3: `predict()` 
48. Simple Linear Regression Python - Step 4A: Visualizing Training Set Results with `matplotlib` 
49. Simple Linear Regression Python - Step 4B: Training Set Visualization Interpretation 
50. Simple Linear Regression Python - Additional Lecture  
51. Simple Linear Regression R  - Step 1: Get the Dataset  
52. Simple Linear Regression R - Step 2: Train `lm()`, Predict Single Result`predict()` and Visualization `ggplot()`  
53. Simple Linear Regression R - Step 3: Predict Test Set Results `predict()` 
54. Simple Linear Regression R - Step 4A: Visualizing Training Set Results with `ggplot2` 
55. Simple Linear Regression R - Step 4B:  Visualizing Training Set Results with `ggplot2` continued... 
56. Simple Linear Regression R - Step 4C: Visualizing Test Set Results with `ggplot2` 

### Section 7: Multiple Linear Regression
57. Dataset + Business Problem Description 
58. Multiple Linear Regression Intuition  
59. Assumptions Of Linear Regression 
60. Multiple Linear Regression Intuition - Step 3  
61. Multiple Linear Regression Intuition - Step 4  
62. Understanding The P Value  
63. Multiple Linear Regression Intuition - Step 5  
64. Multiple Linear Regression Python - Step 1A: Importing the Dataset  
65. Multiple Linear Regression Python - Step 1B: Reading the Dataset `pandas.read_csv()` 
66. Multiple Linear Regression Python - Step 2A: Data Preprocessing `ColumnTransformer` `OneHotEncoder` `test_train_split()` 
67. Multiple Linear Regression Python - Step 2B: Data Preprocessing (continued...)  
68. Multiple Linear Regression Python - Step 3A: Create Regressor Object `LinearRegression()`  
69. Multiple Linear Regression Python - Step 3B: Training the Regression Model `fit()`  
70. Multiple Linear Regression Python - Step 4A: Predicting Single Result `predict()`  
71. Multiple Linear Regression Python - Step 4B: Predicting Test Set `predict()` 
72. Multiple Linear Regression Python - Backward Elimination 
73. Multiple Linear Regression Python - Extra Content  
74. Multiple Linear Regression R - Step 1A: Read the Dataset `read.csv()`  
75. Multiple Linear Regression R - Step 1B: Data Preprocessing  `factor()`  `sample.split()` `scale()`
76. Multiple Linear Regression R - Step 2A: Create Regressor Object `lm()`  
77. Multiple Linear Regression R - Step 2B: View Regressor Info `summary()`  
78. Multiple Linear Regression R - Step 3: Predict on Test Set `predict()` 
79. Multiple Linear Regression R - Backward Elimination Homework!  
80. Multiple Linear Regression R - Backward Elimination Homework Solution 
81. Multiple Linear Regression R - Automatic Backward Elimination (Quiz 3: Multiple Linear Regression Quiz) 

### Section 8: Polynomial Regression
82. Polynomial Regression Intuition 
83. Polynomial Regression Python - Step 1A: Get the Dataset  
84. Polynomial Regression Python - Step 1B: Read the Dataset `pandas.read_csv()` 
85. Polynomial Regression Python - Step 2A: Train `LinearRegression()` `fit`  
86. Polynomial Regression Python - Step 2B: Train `PolynomialFeatures()`  `fit_transform()` `LinearRegression()` `fit()` 
87. Polynomial Regression Python - Step 3A: Basic Visualization 
88. Polynomial Regression Python - Step 3B: Advanced Visualization 
89. Polynomial Regression Python - Step 4A: Linear Regression Prediction  
90. Polynomial Regression Python - Step 4B: Compare Against Polynomial Regression Predictions 
91. Polynomial Regression R - Step 1A: Get Dataset  
92. Polynomial Regression R - Step 1B: Data Preprocessing `read.csv()` `sample.split()` `scale()` 
93. Polynomial Regression R - Step 2A: Train Linear Regression Model as a Baseline `lm()` 
94. Polynomial Regression R - Step 2B: Train Polynomial Regression to Compare `lm()` 
95. Polynomial Regression R - Step 3A: Visualizing Linear Regression Results with `ggplot2`  
96. Polynomial Regression R - Step 3B: Adding Linear Regression Line with `ggplot2` 
97. Polynomial Regression R - Step 3C: Visualizing Polynomial Results with `ggplot2` 
98. Polynomial Regression R - Step 4A: Predicting a New Result with Linear Regression `predict()` 
99. Polynomial Regression R - Step 4B: Predicting a New Result with Polynomial Regression `predict()` 
100. R Regression Template - Step 1: Data Preprocessing `read.csv()`  `sample.split()`  `scale()`  
101. R Regression Template -  Step 2: Fitting Regression, Prediction and Visualization  (Quiz 4: Polynomial Regression Quiz)  

### Section 9: Support Vector Regression (SVR) 
102. SVR Intuition (Updated!)  
103. Heads Up On Non Linear SVR 
104. SVR Python - Step 1A: Data Preprocessing Overview 
105. SVR Python - Step 1B: Importing the Libraries and Dataset 
106. SVR Python - Step 2A: Feature Scaling Overview 
107. SVR Python -  Step 2B: `numpy.reshape()`  
108. SVR Python - Step 2C: `StandardScaler()` `fit_transform()` 
109. SVR Python - Step 3: Create Regressor Model `SVR()` and Train `fit()` 
110. SVR Python - Step 4: Predict New Result on Scaled Features `predict()`   
111. SVR Python - Step 5A: Visualizing SVR Results in the Original Scale  
112. SVR Python - Step 5B: Visualizing SVR Results (High Resolution Version)  
113. SVR R - Step 1: Data Preprocessing  `read.csv()`  `sample.split()` `scale()` and Training the SVR `svr()` 
114. SVR R - Step 2: Predicting New Result `predict()` and Visualizing SVR Results with `ggplot2` (Quiz 5: SVR Quiz)  

### Section 10: Decision Tree Regression
115. Decision Tree Regression Intuition 
116. Decision Tree Regression Python - Step 1A: Get the Dataset  
117. Decision Tree Regression Python - Step 1B: Data Preprocessing `LabelEncoder()` `ColumnTransformer()` `OneHotEncoder()` 
118. Decision Tree Regression Python - Step 2: Train `DecisionTreeRegressor()`  `DecisionTreeClassifier()` `fit()`  
119. Decision Tree Regression Python - Step 3: Predictions `predict()`
120. Decision Tree Regression Python - Step 4: Visualizing Decision Tree Regression Results with `matplotlib` 
121. Decision Tree Regression R - Step 1: Data Preprocessing `read.csv` `sample.split()` `scale()`  
122. Decision Tree Regression R - Step 2: Fitting Decision Tree Regression to the Dataset: `rpart()` and Predictions `predict()` 
123. Decision Tree Regression R - Step 3: Visualizing Results with `ggplot2` 
124. Decision Tree Regression R - Step 4: Visualizing Results with `ggplot2` (High Resolution) (Quiz 6: DT Regression Quiz) 

### Section 11: Random Forest Regression  
125. Random Forest Regression Intuition  
127. Random Forest Regression Python: `RandomForestRegressor()`  `fit()` `predict()` 
128. Random Forest Regression R - Step 1: Data Preprocessing `read.csv()` `sample.split()` `scale()` 
129. Random Forest Regression R - Step 2: Fitting Random Forest Regression `randomForest` and Visualizing Results with `ggplot2` 
130. Random Forest Regression R - Step 3: Predicting New Result with RF Regression `predict()` (Quiz 7: RF Regression Quiz) 

### Section 12: Evaluating Regression Models Performance
131. R-Squared Intuition 
132. Adjusted R-Squared Intuition (Quiz 8: Evaluating Regression Models Performance Quiz)

### Section 13: Regression Model Selection Python
133. Make Sure You Have This Model Selection Folder Ready 
134. Preparation Of The Regression Code Templates - Step 1 
135. Preparation Of The Regression Code Templates - Step 2  
136. Preparation Of The Regression Code Templates - Step 3 
137. Preparation Of The Regression Code Templates - Step 4 
138. Demo Regression Code Templates! - Step 1: Multiple Linear Regression 
139. Demo Regression Code Templates! - Step 2: Polynomial Regression, SVR, DT Regression, RF Regression 
140. Conclusion Of Part 2 - Regression  

### Section 14: Regression Model Selection R
141. Evaluating Regression Models Performance - Homework's Final Part (Backward Elimination)   
142. Interpreting Linear Regression Coefficients  
143. Conclusion Of Part 2 - Regression (Pros & Cons, Hyperparameter Tuning, Regularization) 

### Section 15: Part 3 - Classification
144. Welcome To Part 3   Classification 
145. What Is Classification? 

### Section 16: Logistic Regression
146. Logistic Regression Intuition 
147. Maximum Likelihood  
148. Logistic Regression Python - Step 1A: Overview  
149. Logistic Regression Python - Step 1B: Get the Data 
150. Logistic Regression Python - Step 2A: Importing the Libraries 
151. Logistic Regression Python - Step 2B: Preprocessing `train_test_split()`  `StandardScaler()` 
152. Logistic Regression Python - Step 3A: Create Regressor Object: `LogisticRegression()`   
153. Logistic Regression Python - Step 3B: Train Logistic Regression on the Training Set `fit()`  
154. Logistic Regression Python - Step 4A: Predictions Overview `predict()`  `predict_log_proba()`   `predict_proba()` 
155. Logistic Regression Python - Step 4B: Predicting Test Set Results: `predict()` 
156. Logistic Regression Python - Step 5: Comparing Predictions vs Actuals `predict()` 
157. Logistic Regression Python - Step 6A: Confusion Matrix & Accuracy Score Overview 
158. Logistic Regression Python - Step 6B: Confusion Matrix `confusion_matrix()` and Accuracy Score `accuracy_score()` 
159. Logistic Regression Python - Step 7A: Visualizing Training Set Results  
160. Logistic Regression Python - Step 7B: Visualizing Training Set Results (continued...) 
161. Logistic Regression Python - Step 7C: Visualizing Test Set Results 
162. Logistic Regression Python - Step 7:Visualizing Test Set Results (continued...) 
163. Logistic Regression R - Step 1: Data Preprocessing `read.csv` `sample.split()` `scale()`  
164. Logistic Regression R - Step 2: Fitting Logistic Regression  to the Training Set `glm()`
165. Logistic Regression R - Step 3: Predicting the Test Results `predict()` 
166. Logistic Regression R - Step 4: Making the Confusion Matrix with `table()` 
167. Warning - Update: `ElemStatLearn` Package  
168. Logistic Regression R - Step 5A: Visualizing Training Set Results 
169. Logistic Regression R - Step 5B: Visualizing Training Set Results (continued...) 
170. Logistic Regression R - Step 5C: Visualizing Test Set Results 
171. Logistic Regression R - Step 5D: Visualizing Test Set Results (continued...) 
172. R Classification Template  
173. Machine Learning Regression And Classification Extra (Quiz 9: Logistic Regression Quiz)  
174. Extra Content: Logistic Regression Practical Case Study 

### Section 17: K-Nearest Neighbors (KNN)
175. K-Nearest Neighbor Intuition  
176. K-NN Python - Step 1: Intro [API Reference |scikit-learn.org](https://scikit-learn.org/stable/api/index.html) and [sklearn.neighbors.NearestNeighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html#sklearn.neighbors.NearestNeighbors)
177. K-NN Python - Step 2: Data Pre-Processing `train_test_split()` `StandardScaler()` `KNeighborsClassifier()` `fit()` 
178. K-NN Python - Step 3: Predictions `predict()` and Visualizing the Results with `matplotlib` 
179. K-NN R - Step 1: Data Pre-Processing `factor()` `sample.split()` `scale()`    
180. K-NN R - Step 2: Model Training `knn()` and Evaluation with Confusion Matrix `table()`
181. K-NN R - Step 3: Visualizing the Training Set & Test Results with `ElemStatLearn` (Quiz 10: K-Nearest Neighbor Quiz)  

### Section 18: Support Vector Machine (SVM)
182. SVM Intuition  
183. SVM Python - Step 1: Preprocessing `train_test_split() ` `StandardScaler()` `fit_transform()` `SVC()` `fit()`  `predict()` 
185. SVM Python - Step 3: Visualization Training & Test Set Results with `matplotlib` 
186. SVM R - Step 1: Data Preprocessing `factor()` `sample.split()` `scale()` 
187. SVM R - Step 2: Model Training with  `svm()` from `e1071` package & Visualization with `ElemStatLearn` (Quiz 11: SVM Quiz) 

### Section 19: Kernel SVM
188. Kernel SVM Intuition  
189. Mapping To A Higher Dimension  
190. The Kernel Trick  
191. Types Of Kernel Functions 
192. Non-Linear Kernel SVR (Advanced)  
193. Kernel SVM Python - Step 1: Data Pre-Processing: `train_test_split()` `StandardScaler()` `fit_transform()`  
194. Kernel SVM Python - Step 2: Model Training `sklearn.svm.SVC()` `predict()` `confusion_matrix` `matplotlib` 
195. Kernel SVM R - Step 1: Data Pre-Processing `factor()` `sample.split()` `scale()`  
196. Kernel SVM R - Step 2:  Fitting Kernel SVM to the Training Set `svm()`  `predict()` Confusion Matrix `table()` 
197. Kernel SVM R - Step 3: Visualizing Training and Test Results with `ElemStatLearn` (Quiz 12: Kernel SVM Quiz) 

### Section 20: Naïve Bayes
198. Bayes Theorem   
199. Naïve Bayes Intuition  
200. Naïve Bayes Intuition (Challenge Reveal)  
201. Naïve Bayes Intuition (Extras)  
202. Naïve Bayes Python -  Step 1: Data Pre-Processing `train_test_split()` `StandardScaler()`  `fit_transform()` `transform()`  
203. Naïve Bayes Python - Step 2: Training  `GaussianNB()` `fit()` `predict()` `confusion_matrix()`  `accuracy_score()` 
204. Naïve Bayes Python - Step 3: Visualization with `matplotlib` 
205. Naïve Bayes R - Step 1: Data Pre-Processing `factor()` `sample.split()` `scale()` 
206. Naïve Bayes R - Step 2: Training `naiveBayes()` `e1071` `predict()`, Confusion Matrix `table()` 
207. Naïve Bayes R - Step 3: Visualization and Training and Test Set Results with `ElemStatLearn` library (Quiz 13: Naïve Bayes Quiz) 

### Section 21: Decision Tree Classification
208. DT Classification Intuition 
209. DT Classification Python - Step 1: Data Pre-Processing: `train_test_split()` `StandardScaler()` `fit_transform()`   
210. DT Classification Python -  Step 2: `DecisionTreeClassifier()` `fit()` `predict()` `confusion_matrix()` `accuracy_score()` 
211. DT Classification R - Step 1: Data Pre-Processing `factor()`  `sample.split()`  `scale()` and Fitting DT Classifier `rpart()`  
212. DT Classification R - Step 2: Prediction `predict()`, Confusion Matrix `table()`, Visualization  with `ElemStatLearn` Library 
213. DT Classification R - Step 3: Plot the Decision Tree `plot()`  `text()` (Quiz 14: Decision Tree Classification Quiz)  

### Section 22: Random Forest Classification
214. RF Classification Intuition  
215. RF Classification Python - Step 1: Pre-Processing `train_test_split()`  `StandardScaler()`  `fit_transform()`  `transform()`  
216. RF Classification Python - Step 2: `RandomForestClassifier()`  `fit()` `predict()`  `confusion_matrix()`  `accuracy_score()`
217. RF Classification R - Step 1: Pre-Processing `factor()`  `sample.split()`  `scale()`  
218. RF Classification R - Step 2: Model Training `randomForest()`, Prediction `predict()` Confusion Matrix `table()`
219. RF Classification R - Step 3: Visualization `ElemStatLearn` (Quiz 15: Random Forest Classification Quiz)

### Section 23: Classification Model Selection Python
220. Make Sure You Have This Model Selection Folder Ready 
221. Confusion Matrix & Accuracy Ratios  
222. Demo Classification Code Templates - Step 1: Get the Dataset  
223. Demo Classification Code Templates - Step 2: Templates Logistic Regression, KNN, SVM, Kernel SVM, Naïve Bayes, DT, RF
224. Demo lassification Code Templates - Step 3: Google Colab 
225. Demo Classification Code Templates - Step 4: Decision Tree Slightley Beats Kernel SVM

### Section 24: Evaluating Classification Models Performance
226. Type I and Type II Errors  
227. Accuracy Paradox  
228. CAP Curve  
229. CAP Curve Analysis  
230. Conclusion Of Part 3 - Classification: Pros & Cons, Model Selection & How to Improve Performance

### Section 25: Part 4 - Clustering
231. Welcome To Part 4 - Clustering  

### Section 26: K-Means Clustering
232. What Is Clustering? (Supervised vs Unsupervised Learning)  
233. K-Means Clustering Intuition  
234. The Elbow Method  
235. K Means++  
236. K-Means Clustering Python - Step 1A: Get the Dataset  
237. K-Means Clustering Python - Step 1B: Overview 
238. K-Means Clustering Python - Step 2A: Importing the Libraries 
239. K-Means Clustering Python - Step 2B: Reading the Dataset 
240. K-Means Clustering Python - Step 3A: Using the Elbow Method to Find The Optimal Number of Clusters   
241. K-Means Clustering Python - Step 3B: Elbow Method to Find The Optimal Number of Clusters (continued...) 
242. K-Means Clustering Python - Step 3C: Plot the Graph 
243. K-Means Clustering Python - Step 4: Training the K-Means Model `KMeans()` `fit_predict()` 
244. K-Means Clustering Python - Step 5A: Visualizing the Clusters with `matplotlib` 
245. K-Means Clustering Python - Step 5B: Visualizing the Clusters with `matplotlib` (continued...) 
246. K-Means Clustering Python - Step 5C: Cluster Analysis 
247. K-Means Clustering R - Step 1: Importing the Dataset & Use Elbow Method to Find the Optimal Number of Clusters  
248. K-Means Clustering R - Step 2: Fitting K-Means, Visualizing Clusters, Cluster Analysis (Quiz 17: K-Means Clustering Quiz) 

### Section 27: Hierarchical Clustering
249. Hierarchical Clustering Intuition    
250. Hierarchical Clustering How Dendrograms Work  
251. Hierarchical Clustering Python - Step 2A: Dendrogram `scipy.cluster.hierarchy` `scipy.cluster.hierarchy.linkage()`  
252. Hierarchical Clustering Python - Step 2B: Using the Dendrogram to Find the Optimal Number of Clusters   
253. Hierarchical Clustering Python - Step 2C: Using the Dendrogram to Find the Optimal Number of Clusters (continued...)  
254. Hierarchical Clustering Python - Step 3A: Training HC model `sklearn.cluster.AgglomerativeClustering()` `fit_predict()`    
255. Hierarchical Clustering Python - Step 3B: Visualizing the Clusters   
256. Hierarchical Clustering R - Step 1: Importing the Dataset   
257. Hierarchical Clustering R - Step 2: Using the Dendrogram to Find the Optimal Number of Clusters `hclust()` `plot()`  
258. Hierarchical Clustering R - Step 3: Fitting Hierarchical Clustering to the Dataset `cutree()`   
259. Hierarchical Clustering R - Step 4: Visualizing the Clusters `clusplot()`    
260. Hierarchical Clustering R - Step 5: Cluster Analysis (Quiz 18: Hierarchical Clustering Quiz)    
261. Conclusion Of Part 4 - Clustering: K-Means and Hierarchical Clustering Pros & Cons 

### Section 28: Part 5 - Association Rule Learning
264. Welcome To Part 5 - Association Rule Learning 
265. Apriori Intuition  
266. Apriori Python - Step 1: Get the Dataset 
267. Apriori Python - Step 2: Data Pre-Processing `read_csv()` 
268. Apriori Python - Step 3: Training the Apriori Model on the Dataset `apyori.apriori()
269. Apriori Python - Step 4: Visualizing the Results 
270. Apriori R - Step 1: Data Pre-Processing with `arules` Package  
271. Apriori R - Step 2: Training Apriori on the Dataset `apriori()
272. Apriori R - Step 3: Visualizing the Results (Quiz 19: Apriori Quiz)  
273. Eclat Intuition 
274. Eclat Python: Data Pre-Processing, Training the Eclat Model `apyori.apriori()`, Visualizing the Results  
275. Eclat R: Data Pre-Processing `itemFrequencyPlot()`, Training `eclat()`, Visualization `inspect()` (Quiz 20: Eclat Quiz)  

### Section 31: Part 6 - Reinforcement Learning 
276. Welcome To Part 6 - Reinforcement Learning 

### Section 32: Upper Confidence Bound (UCB)
277. The Multi-Armed Bandit Problem 
278. Upper Confidence Bound (UCB) Intuition  
279. Upper Confidence Bound Python - Step 1: Overview  
280. Upper Confidence Bound Python - Step 2: Data Pre-Processing 
281. Upper Confidence Bound Python - Step 3: Implementing UCB 
282. Upper Confidence Bound Python - Step 4: Implementing UCB (continued...)  
283. Upper Confidence Bound Python - Step 5: Select Advertisement with Maximum UCB ("Huge Value Trick")  
285. Upper Confidence Bound Python - Step 7: Visualizing the Results with `matplotlib` 
286. Upper Confidence Bound R - Step 1: Overview  
287. Upper Confidence Bound R - Step 2: Implementing UCB   
288. Upper Confidence Bound R - Step 3: Choosing Advertisement with Maximum UCB "Huge Value Trick" (Quiz 21: UCB Quiz) 

### Section 33: Thompson Sampling
290. Thompson Sampling Intuition  
291. Algorithm Comparison: UCB vs Thompson Sampling  
292. Thompson Sampling Python - Step 1: Overview  
293. Thompson Sampling Python - Step 2: Implementing Thompson Sampling 
294. Thompson Sampling Python - Step 3: Select the Advertisement  With the Highest $\theta_i(n)$
295. Thompson Sampling Python - Step 4: Visualizing the Results 
296. Additional Resource For This Section  
297. Thompson Sampling R - Step 1: Implementing Thompson Sampling  
298. Thompson Sampling R - Step 2: Visualizing the Results (Quiz 22: Thompson Sampling Quiz)  

### Section 34: Part 7 - Natural Language Processing
299. Welcome To Part 7 - Natural Language Processing  
301. Types Of Natural Language Processing  
302. Classical vs Deep Learning Models  
303. Bag-Of-Words Model  
304. NLP Python - Step 1: Get the Dataset  
305. NLP Python - Step 2: Importing the Libraries 
306. NLP Python - Step 3: Data Cleaning `re.sub()` 
307. NLP Python - Step 4: Data Cleaning `nltk.corpus.stopwords()` `nltk.stem.porter.PortStemmer()` 
308. NLP Python - Step 5: Bag of Words `feature_extraction.text.CountVectorizer()` `fit_transform()` 
309. NLP Python - Step 6: Naive Bayes `GaussianNB()` `predict()` `confusion_matrix()` `accuracy_score()` 
310. NLP Python - Extra  
311. Homework Challenge  
312. NLP R - Step 1: Importing the Dataset `read.delim()`  
313. Warning - Update 
314. NLP R - Step 2: Data Cleaning `VCorpus()`
315. NLP R - Step 3: Data Cleaning `tm_map()`  `content_transformer(tolower)` 
316. NLP R - Step 4: Data Cleaning `removeNumbers()` 
317. NLP R - Step 5: Data Cleaning `removePunctuation()` 
318. NLP R - Step 6: Stop Words from `SnowballC` Package `stopwords()` 
319. NLP R - Step 7: Stemming To Get Root Word `stemDocument` 
320. NLP R - Step 8: Removing Whitespace `stripWhitespace
321. NLP R - Step 9: Creating the Bag of Words Model `DocumentTermMatrix()` `removeSparseTerms()` 
322. NLP R -  Step 10: Training RF Classification Model `randomForest()`, Prediction `predict()`, Evaluation `table()` 
323. Homework Challenge (Quiz 23: NLP Quiz)

### Section 35: Part 8 - Deep Learning
324. Welcome To Part 8 - Deep Learning  
325. What Is Deep Learning? (Quiz 24: Deep Learning Quiz)  

### Section 36: Artificial Neural Networks
326. Plan Of Attack  
327. The Neuron  
328. The Activation Function  
329. How Do Neural Networks Work?  
330. How Do Neural Networks Learn?  
331. Gradient Descent  
332. Stochastic Gradient Descent 
333. Backpropagation  
334. Business Problem Description 
335. ANN Python - Step 1: Getting the Dataset 
336. ANN Python - Step 2: Data Pre-Processing `LabelEncoder()`  `OneHotEncoder()`  `train_test_split()` `StandardScaler()` 
337. ANN Python - Step 3: "Build the Brain" Building the ANN Overview `tf.keras.models.Sequential()` `tf.keras.layers.Dense()` 
338. ANN Python - Step 4: "Make the Brain Smart"Training the ANN `compile()`  `fit()` 
339. ANN Python - Step 5: "Using the Brain" `predict()` and Evaluating `confusion_matrix()` `accuracy_score()` 
340. ANN R - Step 1: Importing the Dataset & Data Preprocessing `as.numeric()` `sample.split()` `scale()`  
341. ANN R - Step 2: Fitting ANN to the Training Set `h2o.init()` 
342. ANN R - Step 3: Fitting ANN to the Training Set `h2o.deeplearning()` 
343. ANN R - Step 4 (Last Step): Predicting the Test Set Results `h2o.predict()` and Confusion Matrix `table()` 
344. Deep Learning Additional Content  
345. Extra Content: Ann Case Study (Quiz 25: ANN Quiz)

### Section 37: Convolutional Neural Networks
346. Plan Of Attack  
347. What Are Convolutional Neural Networks?  
348. Step 1 - Convolution Operation  
349. Step 1(B) - ReLu Layer  
350. Step 2 - Pooling  
351. Step 3 - Flattening  
352. Step 4 - Full Connection  
353. Summary  
354. Softmax & Cross-Entropy  
355. CNN Python - Step 1: Overview  
356. CNN Python - Step 2: Data Pre-Processing `ImageDataGenerator()
357. CNN Python - Step 3: "Building the Brain with Eyes" Initializing the CNN, Convolution, Pooling, Flattening, Full Connection, Output Layer 
358. CNN Python - Step 4: "Making the Brain Smart" Compiling `compile()` and Training `fit()` 
359. CNN Python - Step 5: Deploy CNN to Make Singe Prediction  
360. CNN Python - Final Demo with Google Colab and Jupyter Notebook  
361. Deep Learning Additional Content \#2  (Quiz 26: CNN Quiz) 

### Section 38: Principal Component Analysis (PCA)
362. Welcome To Part 9 - Dimensionality Reduction  
363. Principal Component Analysis (PCA) Intuition  
364. PCA Python - Step 1: Overview  
365. PCA Python - Step 2: Training `LogisticRegression()` `fit()` `predict()` `confusion_matrix()` `accuracy_score()` `matplotlib` 
366. PCA R - Step 1: Data Pre-Processing Data-Preprocessing `sample.split()` `scale()`  
367. PCA R - Step 2: Applying the PCA `preProcess()` `predict()` 
368. PCA R - Step 3: Fitting SVM `svm()` `predict()`, Confusion Matrix `table()`, Visualization `ElemStatLearn` (Quiz 27: PCA Quiz)  

### Section 40: Linear Discriminant Analysis (LDA)
369. Linear Discriminant Analysis (LDA) Intuition  
370. LDA Python 
371. LDA R  (Quiz 28: LDA Quiz)  

### Section 41: Kernel PCA
372. Kernel PCA Python  
373. Kernel PCA R  

### Section 42: Part 10 - Model Selection & Boosting
374. Welcome To Part 10 - Model Selection & Boosting 

### Section 43: Model Selection 
375. K-Fold Cross-Validation Intuition 
376. Bias-Variance Tradeoff  
378. Grid Search Python  
379. K-Fold Cross Validation R  
380. Grid Search R  

### Section 44: XGBoost
381. XGBoost Python  
382. Model Selection And Boosting Additional Content  
383. XGBoost R  

### Section 45: Annex - Logistic Regression (Long Explanation)
384. Logistic Regression Intuition  

### Section 46: Congratulations! Don't Forget Your Prize
385. Huge Congrats For Completing The Challenge! 
386. Bonus: How To Unlock Top Salaries (Live Training)  
